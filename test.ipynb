{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the ticker symbol and date range\n",
    "ticker = \"AAPL\"\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days=30)\n",
    "\n",
    "# Fetch the data\n",
    "apple_data = yf.download(ticker, start=start_date.strftime(\"%Y-%m-%d\"), end=end_date.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# Display the data\n",
    "print(apple_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"AAPL\"\n",
    "interval = \"1m\"  # Smallest interval\n",
    "\n",
    "# Fetch data for the last 7 days\n",
    "apple_data = yf.download(tickers=ticker, period=\"7d\", interval=interval)\n",
    "\n",
    "# Display the first few rows of data\n",
    "print(apple_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fetch Apple's 1-minute data over 7 days\n",
    "ticker = [\"AAPL\", \"NVDA\", \"MSFT\", \"AMZN\", \"GOOG\", \"META\", \"TSLA\", \"AVGO\", \"BRK-B\", \"WMT\"]\n",
    "interval = \"1m\"\n",
    "period = \"1d\"\n",
    "\n",
    "def predict_stock(ticker):\n",
    "    data = yf.download(tickers=ticker, period=period, interval=interval)\n",
    "\n",
    "    # Extract closing prices\n",
    "    closing_prices = data[\"Close\"].dropna()\n",
    "\n",
    "    train = closing_prices[:-26]  \n",
    "    test = closing_prices[-26:]\n",
    "\n",
    "    # Fit the ARIMA model\n",
    "    model = ARIMA(train, order=(5, 1, 2))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Forecast for the 7th day\n",
    "    forecast = model_fit.forecast(steps=len(test))\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(closing_prices.index, closing_prices, label=\"Actual Data (Last 2 Days)\")\n",
    "    plt.plot(test.index, forecast, label=\"Predicted Data (7th Day)\", linestyle='--')\n",
    "    plt.title(f\"{ticker} Stock Price: Actual vs Predicted (ARIMA)\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plots = [predict_stock(tick) for tick in ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Ticker details\n",
    "tickers = [\"AAPL\", \"NVDA\", \"MSFT\", \"AMZN\", \"GOOG\", \"META\", \"TSLA\", \"AVGO\", \"BRK-B\", \"WMT\"]\n",
    "interval = \"1m\"\n",
    "period = \"1d\"\n",
    "\n",
    "results = []  # Store results for each ticker\n",
    "\n",
    "def predict_future(model, last_data_point, scaler, n_predictions=10):\n",
    "    # Use the last data point to start predicting the future\n",
    "    predictions = []\n",
    "    current_input = last_data_point\n",
    "\n",
    "    for _ in range(n_predictions):\n",
    "        \n",
    "        # Predict the next value\n",
    "        next_prediction = model.predict(np.array(current_input[-1]).reshape(-1, 1))\n",
    "        predictions.append(next_prediction[0])\n",
    "        \n",
    "        # Update current input by appending the predicted value\n",
    "        current_input = np.append(current_input[1:], next_prediction)\n",
    "    \n",
    "    predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "    return predictions\n",
    "\n",
    "def plot_future_predictions(predictions, data, future_periods=10):\n",
    "    # Create future dates (Assuming the last date is continuous)\n",
    "    last_date = data.index[-1]\n",
    "    future_dates = [last_date + np.timedelta64(i, 'm') for i in range(1, future_periods + 1)]\n",
    "    \n",
    "    # Plot the future predictions\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(data.index, data[\"Close\"], label=\"Actual Data\")\n",
    "    plt.plot(future_dates, predictions, label=\"Future Predictions\", linestyle=\"--\", color=\"red\")\n",
    "    plt.title(\"Stock Price: Actual vs Future Predictions\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def predict_stock(ticker):\n",
    "    # Download stock data\n",
    "    data = yf.download(tickers=ticker, period=period, interval=interval)\n",
    "\n",
    "    # Extract and clean the closing prices\n",
    "    closing_prices = data[\"Close\"].dropna().values.reshape(-1, 1)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(closing_prices)\n",
    "\n",
    "    # Prepare training and testing data\n",
    "    train_size = len(scaled_prices) - 10\n",
    "    train, test = scaled_prices[:train_size], scaled_prices[train_size:]\n",
    "\n",
    "    # Create input-output datasets\n",
    "    def create_dataset(data):\n",
    "        x, y = [], []\n",
    "        for i in range(len(data) - 1):\n",
    "            x.append(data[i][0])\n",
    "            y.append(data[i + 1][0])\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    X_train, y_train = create_dataset(train)\n",
    "    # X_test, y_test = create_dataset(test, time_step)\n",
    "    X_train = np.array(X_train).reshape(-1, 1)\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    # Build the MLPRegressor model\n",
    "    model = MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=500, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = predict_future(model, X_train, scaler, 10)\n",
    "    plot_future_predictions(predictions, data, 10)\n",
    "\n",
    "    # Make predictions\n",
    "    # predictions = model.predict(X_test)\n",
    "    # predictions = scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "    # Inverse transform actual test data\n",
    "    # y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "    # Record key values\n",
    "    # last_train_price = closing_prices[train_size - 1][0]\n",
    "    # last_predicted_price = predictions[-1][0]\n",
    "    # last_actual_price = y_test_actual[-1][0]\n",
    "\n",
    "    # results.append({\n",
    "    #     \"Ticker\": ticker,\n",
    "    #     \"Last Train Price\": last_train_price,\n",
    "    #     \"Predicted Price\": last_predicted_price,\n",
    "    #     \"Actual Price\": last_actual_price\n",
    "    # })\n",
    "\n",
    "    # Plot the results\n",
    "    # plt.figure(figsize=(14, 6))\n",
    "    # plt.plot(data.index[-len(y_test_actual):], y_test_actual, label=\"Actual Data\")\n",
    "    # plt.plot(data.index[-len(predictions):], predictions, label=\"Predicted Data\", linestyle=\"--\")\n",
    "    # plt.title(f\"{ticker} Stock Price: Actual vs Predicted (MLPRegressor)\")\n",
    "    # plt.xlabel(\"Time\")\n",
    "    # plt.ylabel(\"Price (USD)\")\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "# Generate plots and record results for each ticker\n",
    "for tick in tickers:\n",
    "    predict_stock(tick)\n",
    "\n",
    "# Display results\n",
    "# for result in results:\n",
    "#     print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['AAPL', 'MSFT', 'GOOG', 'AMZN', 'TSLA', 'NVDA', 'JPM', 'V', 'PFE', 'KO', 'JNJ', 'DIS', 'BA', 'CAT', 'WMT', 'MCD', 'GE', 'CSCO', 'XOM', 'CVX', 'NKE', 'NFLX', 'UNH', 'PYPL', 'AMD', 'BA', 'IBM', 'INTC', 'GS', 'SPGI', 'T', 'VZ', 'AMGN', 'CVS', 'LMT', 'RTX', 'HD', 'LOW', 'UPS', 'MS', 'BK', 'AXP', 'BLK', 'MO', 'NEE', 'BMY', 'WFC', 'CSX', 'SCHW', 'ZTS', 'MTB', 'PGR', 'DHR', 'TMO', 'ABT', 'SYY', 'SYK', 'HUM', 'MRK', 'GILD', 'MMM', 'USB', 'MTCH', 'AIG', 'UAL']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from core_code.get_fin_info import get_s_p_tickers, get_fin_data\n",
    "from models.lstm.lstm import get_train_test_for_lstm, build_model, predict_future\n",
    "\n",
    "# Ticker details\n",
    "tickers = get_s_p_tickers()\n",
    "interval = \"5m\"\n",
    "period = \"1d\"\n",
    "start = (datetime.today() - timedelta(days=4)).strftime('%Y-%m-%d')\n",
    "end = (datetime.today() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "\n",
    "results = []  # Store results for each ticker\n",
    "\n",
    "def calc_difference(past, future):\n",
    "    dif = future-past\n",
    "    return dif\n",
    "    if dif<0:\n",
    "        return dif\n",
    "    return f\"+{dif}\"\n",
    "\n",
    "def predict_stock(ticker):\n",
    "    # Get stock data\n",
    "    closing_prices = get_fin_data(ticker, start, end, interval)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(closing_prices)\n",
    "\n",
    "    X_train, y_train = get_train_test_for_lstm(scaled_prices)\n",
    "    \n",
    "    # Build the MLPRegressor model\n",
    "    model = build_model(X_train, y_train)\n",
    "    \n",
    "    predictions = predict_future(model, y_train, scaler) # change y_tain to whole data set when real data\n",
    "\n",
    "    # Record key values\n",
    "    last_train_price = scaler.inverse_transform(np.array(X_train[-1][0]).reshape(-1, 1))[0][0]\n",
    "    last_predicted_price = predictions[-1][0]\n",
    "    last_actual_price = scaler.inverse_transform(np.array(scaled_prices[-1][0]).reshape(-1, 1))[0][0]\n",
    "\n",
    "    results.append({\n",
    "        \"Ticker\": ticker,\n",
    "        # \"Last Train Price\": last_train_price,\n",
    "        # \"Predicted Price\": last_predicted_price,\n",
    "        # \"Actual Price\": last_actual_price,\n",
    "        \"Predicted Difference\": calc_difference(last_train_price, last_predicted_price),\n",
    "        \"Actual Difference\": calc_difference(last_train_price, last_actual_price)\n",
    "\n",
    "    })\n",
    "\n",
    "# Generate plots and record results for each ticker\n",
    "for tick in tickers:\n",
    "    predict_stock(tick)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Round to 2 decimal places\n",
    "# df[\"Last Train Price\"] = df[\"Last Train Price\"].round(2)\n",
    "# df[\"Predicted Price\"] = df[\"Predicted Price\"].round(2)\n",
    "# df[\"Actual Price\"] = df[\"Actual Price\"].round(2)\n",
    "\n",
    "# Display the table\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(df['Predicted Difference'], df['Actual Difference'], marker='o', linestyle='-', color='blue')\n",
    "plt.title('Pred vs Act Plot')\n",
    "plt.xlabel('Pred Axis')\n",
    "plt.ylabel('Act Axis')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each pair of values from both columns for the same x-axis index\n",
    "for i in range(len(df)):\n",
    "    plt.scatter(i + 1, df['Predicted Difference'][i], color='blue')  # Plot for Column1\n",
    "    plt.scatter(i + 1, df['Actual Difference'][i], color='red')   # Plot for Column2\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Scatter Plot of Column1 and Column2 at Each Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(model, last_data_point, scaler, n_predictions=1):\n",
    "    # Use the last data point to start predicting the future\n",
    "    predictions = []\n",
    "    current_input = last_data_point\n",
    "\n",
    "    for _ in range(n_predictions):\n",
    "        \n",
    "        # Predict the next value\n",
    "        next_prediction = model.predict(np.array(current_input[-1]).reshape(-1, 1))\n",
    "        predictions.append(next_prediction[0])\n",
    "        \n",
    "        # Update current input by appending the predicted value\n",
    "        current_input = np.append(current_input[1:], next_prediction)\n",
    "    \n",
    "    predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1))\n",
    "    return predictions\n",
    "\n",
    "def plot_future_predictions(predictions, data, future_periods=1):\n",
    "    # Create future dates (Assuming the last date is continuous)\n",
    "    last_date = data.index[-1]\n",
    "    future_dates = [last_date + np.timedelta64(i, 'm') for i in range(1, future_periods + 1)]\n",
    "    \n",
    "    # Plot the future predictions\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(data.index, data[\"Close\"], label=\"Actual Data\")\n",
    "    plt.plot(future_dates, predictions, label=\"Future Predictions\", linestyle=\"--\", color=\"red\")\n",
    "    plt.title(\"Stock Price: Actual vs Future Predictions\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price (USD)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize counters\n",
    "both_above_0 = 0\n",
    "both_below_0 = 0\n",
    "one_above_one_below = 0\n",
    "\n",
    "# Loop through each row and count the conditions\n",
    "for i in range(len(df)):\n",
    "    col1 = df['Predicted Difference'][i]\n",
    "    col2 = df['Actual Difference'][i]\n",
    "\n",
    "    if col1 > 0 and col2 > 0:\n",
    "        both_above_0 += 1\n",
    "    elif col1 < 0 and col2 < 0:\n",
    "        both_below_0 += 1\n",
    "    elif (col1 > 0 and col2 < 0) or (col1 < 0 and col2 > 0):\n",
    "        one_above_one_below += 1\n",
    "\n",
    "# Print the results\n",
    "print(f\"Both dots are above 0: {both_above_0} times\")\n",
    "print(f\"Both dots are below 0: {both_below_0} times\")\n",
    "print(f\"One dot is above 0 while the other is below 0: {one_above_one_below} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "14+9+42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from core_code.get_fin_info import get_s_p_tickers, get_fin_data\n",
    "from models.lstm.lstm import get_train_test_for_lstm\n",
    "\n",
    "# Ticker details\n",
    "tickers = get_s_p_tickers()\n",
    "interval = \"5m\"\n",
    "period = \"1d\"\n",
    "start = (datetime.today() - timedelta(days=4)).strftime('%Y-%m-%d')\n",
    "end = (datetime.today() - timedelta(days=3)).strftime('%Y-%m-%d')\n",
    "\n",
    "closing_prices = get_fin_data(\"aapl\", start, end, interval)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_prices = scaler.fit_transform(closing_prices)\n",
    "\n",
    "print(scaled_prices)\n",
    "train_size = len(scaled_prices) - 1\n",
    "train = scaled_prices[:train_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(data).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "def create_dataset(data):\n",
    "    x, y = [], []\n",
    "    for i in range(len(data) - 1):\n",
    "        x.append(data[i][0])\n",
    "        y.append(data[i + 1][0])\n",
    "    return np.array(x), np.array(y)\n",
    "x, y = create_dataset(np.array(data).reshape(-1,1))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from core_code.get_fin_info import get_s_p_tickers, get_fin_data\n",
    "from models.lstm.lstm import get_train_test_for_lstm, build_model, predict_future\n",
    "from core_code.testing import calc_difference, plot_skatter\n",
    "\n",
    "# Ticker details\n",
    "tickers = get_s_p_tickers()\n",
    "\n",
    "def predict_stock(ticker, start, end, interval):\n",
    "    # Get stock data\n",
    "    closing_prices = get_fin_data(ticker, start, end, interval)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_prices = scaler.fit_transform(closing_prices)\n",
    "\n",
    "    X_train, y_train = get_train_test_for_lstm(scaled_prices)\n",
    "    \n",
    "    # Build the MLPRegressor model\n",
    "    model = build_model(X_train, y_train.ravel())\n",
    "    \n",
    "    predictions = predict_future(model, y_train, scaler) # change y_tain to whole data set when real data\n",
    "\n",
    "    # Record key values\n",
    "    last_train_price = scaler.inverse_transform(np.array(X_train[-1][0]).reshape(-1, 1))[0][0]\n",
    "    last_predicted_price = predictions[-1][0]\n",
    "    last_actual_price = scaler.inverse_transform(np.array(scaled_prices[-1][0]).reshape(-1, 1))[0][0]\n",
    "    return last_train_price, last_predicted_price, last_actual_price\n",
    "\n",
    "ave_act_dif = []\n",
    "profits_005 = []\n",
    "profits_01 = []\n",
    "profits_015 = []\n",
    "for i in range(30):\n",
    "    results = []\n",
    "    act_dif = []\n",
    "    interval = \"5m\"\n",
    "    start = (datetime.today() - timedelta(days=i+1)).strftime('%Y-%m-%d')\n",
    "    end = (datetime.today() - timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "\n",
    "    try:\n",
    "        # Generate plots and record results for each ticker\n",
    "        for ticker in tickers:\n",
    "            last_train_price, last_predicted_price, last_actual_price = predict_stock(ticker, start, end, interval)\n",
    "\n",
    "            predicted_difference = calc_difference(last_train_price, last_predicted_price)\n",
    "            actual_difference = calc_difference(last_train_price, last_actual_price)\n",
    "            act_dif.append(actual_difference)\n",
    "\n",
    "            if predicted_difference>0.005:\n",
    "                print(i, last_train_price, last_predicted_price, last_actual_price)\n",
    "\n",
    "                profits_005.append((i, last_train_price, last_predicted_price, last_actual_price))\n",
    "\n",
    "                if predicted_difference>0.01:\n",
    "                    print(i, last_train_price, last_predicted_price, last_actual_price)\n",
    "\n",
    "                    profits_01.append((i, last_train_price, last_predicted_price, last_actual_price))\n",
    "\n",
    "                    if predicted_difference>0.015:\n",
    "                        print(i, last_train_price, last_predicted_price, last_actual_price)\n",
    "\n",
    "                        profits_015.append((i, last_train_price, last_predicted_price, last_actual_price))\n",
    "\n",
    "            results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Predicted Difference\": predicted_difference,\n",
    "                \"Actual Difference\": actual_difference\n",
    "\n",
    "            })\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(results)\n",
    "        plot_skatter(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if len(act_dif)>0:\n",
    "        ave_act_dif.append((i, sum(act_dif)/len(act_dif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ave_act_dif)\n",
    "print(profits_1)\n",
    "print(profits_2_5)\n",
    "print(profits_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ave_act_dif)\n",
    "print(profits_1)\n",
    "print(profits_2_5)\n",
    "print(profits_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from core_code.get_fin_info import get_s_p_tickers\n",
    "from core_code.testing import calc_difference, plot_skatter, breached_threshold\n",
    "from core_code.prediction import predict_stock\n",
    "\n",
    "# Ticker details\n",
    "tickers = get_s_p_tickers()\n",
    "\n",
    "ave_act_dif = []\n",
    "profits_005 = []\n",
    "profits_01 = []\n",
    "profits_015 = []\n",
    "for i in range(3):\n",
    "    results = []\n",
    "    act_dif = []\n",
    "    interval = \"5m\"\n",
    "    start = (datetime.today() - timedelta(days=i+1)).strftime('%Y-%m-%d')\n",
    "    end = (datetime.today() - timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "\n",
    "    try:\n",
    "        # Generate plots and record results for each ticker\n",
    "        for ticker in tickers:\n",
    "            last_train_price, last_predicted_price, last_actual_price = predict_stock(ticker, start, end, interval)\n",
    "\n",
    "            predicted_difference = calc_difference(last_train_price, last_predicted_price)\n",
    "            actual_difference = calc_difference(last_train_price, last_actual_price)\n",
    "            act_dif.append(actual_difference)\n",
    "\n",
    "            breached_threshold(0.005, profits_005, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "            breached_threshold(0.01, profits_01, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "            breached_threshold(0.015, profits_015, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "\n",
    "            results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Predicted Difference\": predicted_difference,\n",
    "                \"Actual Difference\": actual_difference\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(results)\n",
    "        plot_skatter(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if len(act_dif)>0:\n",
    "        ave_act_dif.append((i, sum(act_dif)/len(act_dif)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from core_code.get_fin_info import get_s_p_tickers\n",
    "from core_code.testing import calc_difference, plot_skatter, breached_threshold\n",
    "from core_code.prediction import predict_stock\n",
    "from core_code.get_fin_info import get_fin_data\n",
    "\n",
    "# Ticker details\n",
    "tickers = get_s_p_tickers()\n",
    "\n",
    "ave_act_dif = {}\n",
    "profits_005 = {}\n",
    "profits_0075 = {}\n",
    "profits_01 = {}\n",
    "profits_015 = {}\n",
    "profits_02 = {}\n",
    "profits_025 = {}\n",
    "for i in range(10):\n",
    "    results = []\n",
    "    act_dif = []\n",
    "    interval = \"5m\"\n",
    "    start = (datetime.today() - timedelta(days=i+1)).strftime('%Y-%m-%d')\n",
    "    end = (datetime.today() - timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "\n",
    "    try:\n",
    "        # Generate plots and record results for each ticker\n",
    "        for ticker in tickers:\n",
    "            # Get stock data\n",
    "            closing_prices = get_fin_data(ticker, start, end, interval)\n",
    "            last_train_price, last_predicted_price, last_actual_price = predict_stock(closing_prices)\n",
    "\n",
    "            predicted_difference = calc_difference(last_train_price, last_predicted_price)\n",
    "            actual_difference = calc_difference(last_train_price, last_actual_price)\n",
    "            act_dif.append(actual_difference)\n",
    "\n",
    "            breached_threshold(0.005, profits_005, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "            breached_threshold(0.0075, profits_0075, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "            breached_threshold(0.01, profits_01, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "            breached_threshold(0.015, profits_015, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "            breached_threshold(0.02, profits_02, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "            breached_threshold(0.025, profits_025, predicted_difference, i, last_train_price, last_predicted_price, last_actual_price)\n",
    "\n",
    "            results.append({\n",
    "                \"Ticker\": ticker,\n",
    "                \"Predicted Difference\": predicted_difference,\n",
    "                \"Actual Difference\": actual_difference\n",
    "            })\n",
    "\n",
    "        # df = pd.DataFrame(results)\n",
    "        # plot_skatter(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    if len(act_dif)>0:\n",
    "        ave_act_dif[i] = sum(act_dif)/len(act_dif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ave_act_dif)\n",
    "print(profits_005)\n",
    "print(profits_01)\n",
    "print(profits_015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dicts = [profits_005, profits_0075, profits_01, profits_015, profits_02, profits_025]\n",
    "for dic in dicts:\n",
    "    averages = {key: np.mean(values) for key, values in dic.items()}\n",
    "\n",
    "    for key, avg in averages.items():\n",
    "        print(f\"Key {key}: S&P_Ave = {ave_act_dif[key]}, Average = {avg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Connect to SQLite database\n",
    "conn = sqlite3.connect(\"data.db\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM stocks_data\", conn)\n",
    "conn.close()  # Close connection\n",
    "\n",
    "def convert_blob(blob):\n",
    "    return np.frombuffer(blob, dtype=np.float64)  # Adjust dtype if needed\n",
    "\n",
    "# Apply conversion to all rows\n",
    "df = df.map(convert_blob)\n",
    "\n",
    "# Convert DataFrame rows into a list of lists\n",
    "list_of_lists = df.values.tolist()  # Extracts all rows as lists\n",
    "\n",
    "# Plot each sublist sequentially\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "colors = ['b', 'g', 'r', 'c', 'm']  # Different colors for each sublist\n",
    "for i, sublist in enumerate(list_of_lists[:5]):  # Only 5 sublists\n",
    "    plt.plot(range(len(sublist)), sublist, color=colors[i % len(colors)], label=f\"Sublist {i+1}\")\n",
    "\n",
    "    # Plot styling\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.title(\"Sequential Plot of 5 Sublists\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from core_code.get_fin_info import get_s_p_tickers\n",
    "from core_code.testing import calc_difference, plot_skatter, breached_threshold\n",
    "from core_code.prediction import predict_stock\n",
    "from core_code.get_fin_info import get_fin_data\n",
    "import sqlite3\n",
    "import itertools\n",
    "\n",
    "tickers = get_s_p_tickers()[:5]\n",
    "tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import yfinance as yf\n",
    "data = yf.download(\n",
    "        tickers=\"MMM\", \n",
    "        start=\"2025-02-10\", \n",
    "        end=\"2025-02-11\", \n",
    "        interval=\"1h\"\n",
    "    )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from core_code.get_fin_info import get_s_p_tickers\n",
    "from core_code.testing import calc_difference, plot_skatter, breached_threshold\n",
    "from core_code.prediction import predict_stock\n",
    "from core_code.get_fin_info import get_fin_data\n",
    "import sqlite3\n",
    "import itertools\n",
    "\n",
    "tickers = get_s_p_tickers()[:2]\n",
    "data_list = []\n",
    "n_days = 2\n",
    "for ticker in tickers:\n",
    "    dates = []\n",
    "    close_val = []\n",
    "    volumn_val = []\n",
    "    for i in range(n_days):\n",
    "        interval = \"90m\"\n",
    "        start = (datetime.today() - timedelta(days=n_days-i)).strftime('%Y-%m-%d')\n",
    "        end = (datetime.today() - timedelta(days=n_days-i-1)).strftime('%Y-%m-%d')\n",
    "        try:\n",
    "            data = get_fin_data(ticker, start, end, interval)\n",
    "            dates.append(data.index.tolist())\n",
    "            close_val.append(data[\"Close\"].to_numpy().flatten().tolist())\n",
    "            volumn_val.append(data[\"Volume\"].to_numpy().flatten().tolist())\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    data_list.append((dates, close_val, volumn_val))\n",
    "\n",
    "# df = pd.DataFrame(data_list)\n",
    "\n",
    "# conn = sqlite3.connect(\"data.db\")  # Creates a database file\n",
    "# df.to_sql(\"stocks_data\", conn, if_exists=\"replace\", index=False)  # Writes DataFrame to a table\n",
    "# conn.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from core_code.get_fin_info import get_s_p_tickers\n",
    "# print(type(get_s_p_tickers()))\n",
    "tickers = random.shuffle(get_s_p_tickers())\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open('data_records.pkl', 'rb') as file:\n",
    "    data_records = pickle.load(file)\n",
    "\n",
    "# Specify the date for which to plot the data\n",
    "plot_date = '2025-02-11'\n",
    "\n",
    "# Number of tickers to plot\n",
    "tickers = list(data_records[plot_date].keys())\n",
    "\n",
    "# Create a figure with a separate subplot for each ticker\n",
    "fig, axes = plt.subplots(len(tickers), 1, figsize=(10, 6 * len(tickers)))\n",
    "\n",
    "# If only one ticker, axes is a single object, so we make it a list\n",
    "if len(tickers) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Loop through each ticker and plot the 'Close' price against the 'Time' for the specified date\n",
    "for ax, ticker in zip(axes, tickers):\n",
    "    stock_data = data_records[plot_date][ticker]\n",
    "    \n",
    "    # Ensure the 'Time' column is in datetime format\n",
    "    stock_data['Time'] = pd.to_datetime(stock_data['Time'])\n",
    "    \n",
    "    # Plot the 'Close' price against the 'Time'\n",
    "    ax.plot(stock_data['Time'], stock_data['Close'], label=ticker)\n",
    "    \n",
    "    # Customize each subplot\n",
    "    ax.set_title(f\"Stock Price of {ticker} on {plot_date}\")\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('Close Price ($)')\n",
    "    ax.legend()\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the pickle file\n",
    "with open('data_records.pkl', 'rb') as file:\n",
    "    data_records = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Load the data\n",
    "with open('data_records.pkl', 'rb') as file:\n",
    "    data_records = pickle.load(file)\n",
    "\n",
    "# Define the output file\n",
    "output_file_train = \"deepar_train_data.jsonl\"\n",
    "output_file_test = \"deepar_test_data.jsonl\"\n",
    "\n",
    "# List to hold DeepAR formatted records\n",
    "deepar_train = []\n",
    "deepar_test = []\n",
    "\n",
    "# Process each date and ticker\n",
    "for date, tickers_data in data_records.items():\n",
    "    for ticker, time_series in tickers_data.items():\n",
    "        try:\n",
    "            # Use varrying lenght datasets\n",
    "            # The random number is chosen so that there is at least 3 hours in the training set and 30 mins in the test\n",
    "            rand_num = random.randint(40, 60)\n",
    "\n",
    "            # Construct DeepAR formatted entry\n",
    "            deepar_train_entry = {\n",
    "                \"start\": time_series[\"Time\"][0].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"target\": [entry for entry in time_series[\"Close\"]][:rand_num]\n",
    "            }\n",
    "\n",
    "            # Construct DeepAR formatted entry\n",
    "            deepar_test_entry = {\n",
    "                \"start\": time_series[\"Time\"][rand_num].strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"target\": [entry for entry in time_series[\"Close\"]][rand_num:]\n",
    "            }\n",
    "\n",
    "            deepar_train.append(deepar_train_entry)\n",
    "            deepar_test.append(deepar_test_entry)\n",
    "        except Exception as e:\n",
    "            _=1\n",
    "\n",
    "# Save to JSONL\n",
    "with open(output_file_train, \"w\") as f:\n",
    "    for record in deepar_train:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "with open(output_file_test, \"w\") as f:\n",
    "    for record in deepar_test:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.torch import DeepAREstimator\n",
    "\n",
    "# Load data from a CSV file into a PandasDataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/AileenNielsen/\"\n",
    "    \"TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "dataset = PandasDataset(df, target=\"#Passengers\")\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Passengers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1949-01-01</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-02-01</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-03-01</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-04-01</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949-05-01</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-08-01</th>\n",
       "      <td>606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-09-01</th>\n",
       "      <td>508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-10-01</th>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-11-01</th>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960-12-01</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            #Passengers\n",
       "Month                  \n",
       "1949-01-01          112\n",
       "1949-02-01          118\n",
       "1949-03-01          132\n",
       "1949-04-01          129\n",
       "1949-05-01          121\n",
       "...                 ...\n",
       "1960-08-01          606\n",
       "1960-09-01          508\n",
       "1960-10-01          461\n",
       "1960-11-01          390\n",
       "1960-12-01          432\n",
       "\n",
       "[144 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.torch import DeepAREstimator\n",
    "\n",
    "# Load data from a CSV file into a PandasDataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/AileenNielsen/\"\n",
    "    \"TimeSeriesAnalysisWithPython/master/data/AirPassengers.csv\",\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "dataset = PandasDataset(df, target=\"#Passengers\")\n",
    "\n",
    "# Split the data for training and testing\n",
    "training_data, test_gen = split(dataset, offset=-36)\n",
    "test_data = test_gen.generate_instances(prediction_length=12, windows=3)\n",
    "\n",
    "# Train the model and make predictions\n",
    "model = DeepAREstimator(\n",
    "    prediction_length=12, freq=\"M\", trainer_kwargs={\"max_epochs\": 1}\n",
    ").train(training_data)\n",
    "\n",
    "forecasts = list(model.predict(test_data.input))\n",
    "\n",
    "# Plot predictions\n",
    "plt.plot(df[\"1954\":], color=\"black\")\n",
    "for forecast in forecasts:\n",
    "  forecast.plot()\n",
    "plt.legend([\"True values\"], loc=\"upper left\", fontsize=\"xx-large\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\olive\\anaconda3\\envs\\algo_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:70: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | Mode  | In sizes                                                         | Out sizes   \n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 26.8 K | train | [[1, 1], [1, 1], [1, 1164, 6], [1, 1164], [1, 1164], [1, 12, 6]] | [1, 100, 12]\n",
      "--------------------------------------------------------------------------------------------------------------------------------\n",
      "26.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.8 K    Total params\n",
      "0.107     Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 50/? [00:03<00:00, 15.96it/s, v_num=37, train_loss=4.950]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 4.94627 (best 4.94627), saving model to 'c:\\\\Users\\\\olive\\\\OneDrive\\\\Documents\\\\GitHub\\\\algo_trading\\\\lightning_logs\\\\version_37\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: |          | 50/? [00:03<00:00, 15.79it/s, v_num=37, train_loss=4.950]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object PyTorchPredictor.predict at 0x000001EC86FDC970>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "from gluonts.dataset.pandas import PandasDataset\n",
    "from gluonts.dataset.split import split\n",
    "from gluonts.torch import DeepAREstimator\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.mx import Trainer\n",
    "\n",
    "# Load JSONL file\n",
    "jsonl_file = \"deepar_train_data.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(jsonl_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Convert to ListDataset format\n",
    "train_dataset = ListDataset(\n",
    "    [{\"target\": entry[\"target\"], \"start\": pd.Timestamp(entry[\"start\"])} for entry in data],\n",
    "    freq=\"5min\"\n",
    ")\n",
    "\n",
    "jsonl_file = \"deepar_test_data.jsonl\"\n",
    "\n",
    "data = []\n",
    "with open(jsonl_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "data[:1]\n",
    "# Convert to ListDataset format\n",
    "test_dataset = ListDataset(\n",
    "    [{\"target\": entry[\"target\"], \"start\": pd.Timestamp(entry[\"start\"])} for entry in data],\n",
    "    freq=\"5min\"\n",
    ")\n",
    "\n",
    "# Train the model and make predictions\n",
    "model = DeepAREstimator(\n",
    "    prediction_length=12, freq=\"5min\", trainer_kwargs={\"max_epochs\": 1}\n",
    ").train(train_dataset)\n",
    "\n",
    "forecasts = model.predict(test_dataset)\n",
    "forecasts\n",
    "# # Plot predictions\n",
    "# plt.plot(df[\"1954\":], color=\"black\")\n",
    "# for forecast in forecasts:\n",
    "#   forecast.plot()\n",
    "# plt.legend([\"True values\"], loc=\"upper left\", fontsize=\"xx-large\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts_array = np.array(list(forecasts))\n",
    "forecasts_array\n",
    "# Generate x-axis values if timestamps are unavailable\n",
    "# x_values = range(len(forecasts_array))\n",
    "# x_values\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(x_values, forecasts_array, label=\"Predicted Values\", linestyle=\"dashed\", color=\"red\")\n",
    "# plt.xlabel(\"Time Step\")\n",
    "# plt.ylabel(\"Forecasted Value\")\n",
    "# plt.title(\"Model Forecasts\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{<class 'pandas._libs.tslibs.timestamps.Timestamp'>}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(jsonl_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "toset = [type(pd.Timestamp(i[\"start\"])) for i in data]\n",
    "\n",
    "print(set(toset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<5 * Minutes>\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_dataset))[\"start\"].freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
